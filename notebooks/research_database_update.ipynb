{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae72ad7c",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9cb902d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook initialized.\n"
     ]
    }
   ],
   "source": [
    "### Load libraries \n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#import sqlite3 as sl\n",
    "import uuid\n",
    "#import csv\n",
    "#import os.path\n",
    "#from os import path\n",
    "import glob\n",
    "#import time\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "from ipywidgets import *\n",
    "from IPython.display import clear_output, display\n",
    "from IPython.core.display import display, HTML\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import qgrid\n",
    "\n",
    "import helpers.research_helpers as app\n",
    "\n",
    "CSV_SEPARATOR = ','     # '\\t'\n",
    "PIPE_SEPARATOR = '|#' \n",
    "\n",
    "TBL_SURVEYS = 'SURVEYS'\n",
    "TBL_MEMBERS = 'MEMBERS'\n",
    "TBL_MEMBERS_TO_SURVEYS = 'MEMBERS_TO_SURVEYS'\n",
    "\n",
    "SURVEYS_COL_SURVEY_ID = 'survey_id'\n",
    "SURVEYS_COL_NAME = 'name'\n",
    "SURVEYS_COL_DATE = 'date'\n",
    "\n",
    "MEMBERS_COL_SURVEY_ID = 'member_id'\n",
    "MEMBERS_COL_FNAME = 'first_name'\n",
    "MEMBERS_COL_LNAME = 'last_name'\n",
    "MEMBERS_COL_EMAIL = 'email'\n",
    "MEMBERS_COL_LAST_SURVEY_DATE = 'last_survey_date'\n",
    "\n",
    "print('Notebook initialized.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca9e9be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../sampling'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.FLDR_SAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d498bd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete_list = pd.read_csv (app.FLDR_SAMPLING + '/AllActive/AllActiveMem.csv' , sep=PIPE_SEPARATOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1720fd15",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "columns = ['member_id', 'expiration_date', 'name_prefix', 'first_name', 'middle_name', 'last_name', 'name_suffix', \n",
    "           'cert_type', 'cert_start_date', 'cert_end_date', 'job_title_freetext', 'companyname', \n",
    "           'shipaddr_1', 'shipaddr_2', 'shipaddr_city', 'shipaddr_state', 'shipaddr_zip', \n",
    "           'shipaddr_country', 'shipaddr_country_desc', 'shipaddr_type', \n",
    "           'email', 'disallow_all_communication', 'disallow_email_communication', 'disallow_phone_communication', \n",
    "           'disallow_regular_mail_communication', 'disallow_third_party_communication', \n",
    "           'job_title', 'job_function', 'employment_status', 'company_size', 'department_size', \n",
    "           'industry_category', 'organization_unit', 'organization_type', 'employee_oversee', 'supervisor_title', \n",
    "           'gender', 'ethnicity', 'education', 'native_language', 'customer_segment', 'title_calculated', \n",
    "           'gender_calculated', 'education_calculated', 'age_calculated', 'ethnicity_calculated', \n",
    "           'state_calculated', 'location_calculated', 'region_calculated', 'pub_private_calculated', \n",
    "           'sample_size_calculated', 'time_zone_calculated']\n",
    "df_trimmed_list = df_complete_list[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2238553",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1229d5c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "783bd3bc",
   "metadata": {},
   "source": [
    "# Load All Active Roster.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16391382",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### Load All Active Roster.csv \n",
    "\n",
    "#df_complete_list = app.load_csv(app.FLDR_SAMPLING + '/All Active Roster.csv')\n",
    "df_complete_list = pd.read_csv (app.FLDR_SAMPLING + '/All Active Roster.csv' , sep=CSV_SEPARATOR)\n",
    "df_complete_list.columns = df_complete_list.columns.str.lower()\n",
    "\n",
    "df_complete_list = df_complete_list.rename(columns=str.lower)\n",
    "df_complete_list = df_complete_list[['member_id','email', 'firstname', 'lastname', 'job_title']]\n",
    "df_complete_list['email'] = df_complete_list['email'].str.lower()\n",
    "df_complete_list['email'] = df_complete_list['email'].str.strip()\n",
    "\n",
    "df_complete_list['member_id'] = df_complete_list['member_id'].astype('string')\n",
    "df_complete_list['email'] = df_complete_list['email'].astype('string')\n",
    "df_complete_list['firstname'] = df_complete_list['firstname'].astype('string')\n",
    "df_complete_list['lastname'] = df_complete_list['lastname'].astype('string')\n",
    "df_complete_list['job_title'] = df_complete_list['job_title'].astype('string')\n",
    "#df_complete_list['last_survey_date'] = df_complete_list['last_survey_date'].astype('category')\n",
    "\n",
    "print(str(len(df_complete_list)) + ' records loaded from ' + app.FLDR_SAMPLING + '/All Active Roster.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeebde3",
   "metadata": {},
   "source": [
    "# Determine which survey directories should be saved to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03b4eb9",
   "metadata": {
    "code_folding": [
     0,
     9,
     13
    ]
   },
   "outputs": [],
   "source": [
    "### OLD - Search file system for survey directories needing to be processed. \n",
    "if False:\n",
    "    if os.path.exists(app.FLDR_SAMPLING + '/SURVEYS.csv'):\n",
    "        df_surveys = pd.read_csv (app.FLDR_SAMPLING + '/SURVEYS.csv' , sep=CSV_SEPARATOR, keep_default_na=False)\n",
    "        df_surveys.columns= df_surveys.columns.str.lower()\n",
    "    else:\n",
    "        df_surveys = pd.DataFrame(columns = ['survey_id','name','date'])\n",
    "    df_surveys['new_entry'] = 0\n",
    "\n",
    "    def get_date_name (row):\n",
    "        new_val = str(row['date']) + '___' + str(row['name'])\n",
    "        return new_val\n",
    "\n",
    "    def get_unprocessed_survey_dirs(df_saved_surveys):\n",
    "        # get list of processed survey dirs\n",
    "\n",
    "        surveys_dict = {}\n",
    "        print('Count of previously processed survey dirs: {}'.format(str(len(df_saved_surveys['name'].values))))\n",
    "\n",
    "        for index, row in df_saved_surveys.iterrows(): \n",
    "            surveys_dict[row[SURVEYS_COL_NAME]] = row[SURVEYS_COL_DATE]\n",
    "\n",
    "        # find potential unprocessed survey dirs by iterating over folder names in s_drive and, \n",
    "        # comparing names to previously processed list\n",
    "        df = pd.DataFrame(columns=['name','date'])\n",
    "\n",
    "        for filename in glob.iglob(app.FLDR_SAMPLING + '/**/*.[cC][sS][vV]', recursive=True):\n",
    "            if 'qualtrics' in filename.lower():\n",
    "\n",
    "                match_date = re.search(r'\\d{4}-\\d{2}-\\d{2}', filename.split('/')[-1])\n",
    "                if match_date != None:\n",
    "                    survey_date = datetime.strptime(match_date.group(), '%Y-%m-%d').date()\n",
    "                else:\n",
    "                    t = os.path.getmtime(filename)\n",
    "                    survey_date = datetime.fromtimestamp(t)\n",
    "\n",
    "                survey_name = filename.split('/')[-2]\n",
    "\n",
    "                # verify survey_name starts with a year AND hasn't already been processed\n",
    "                if survey_name not in surveys_dict:\n",
    "                    surveys_dict[survey_name] = survey_date\n",
    "                    #print('{}, on {}'.format(survey_name, survey_date.strftime('%Y-%m-%d')))\n",
    "                    new_row = {'name':survey_name, 'date': survey_date.strftime('%Y-%m-%d')}\n",
    "                    df = df.append(new_row, ignore_index=True)\n",
    "\n",
    "        if len(df) > 0: # found new records, append to db\n",
    "            return df\n",
    "        else:\n",
    "            df = pd.DataFrame(columns = [SURVEYS_COL_NAME, SURVEYS_COL_DATE])\n",
    "            return df\n",
    "\n",
    "    ### Get a dataframe of surveys that have not been processed\n",
    "    df_unprocessed_survey_dirs = get_unprocessed_survey_dirs(df_surveys)\n",
    "    #print('Count of unprocessed survey dirs: {}'.format(str(len(df_unprocessed_survey_dirs))))\n",
    "    #if df_unprocessed_survey_dirs is None:\n",
    "    #    print('There are no new survey directories to process :)')\n",
    "    #else:\n",
    "    #    # Allow user's to select which surveys, if any, they want to exclude\n",
    "    #    qgrid_sheet_to_keep = app.keep_grid_show_filter(df_unprocessed_survey_dirs, 'name', None, app.KEEP_LIST_SURVEY_DIRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9a7746",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### Search file system for survey directories needing to be processed. \n",
    "\n",
    "if os.path.exists(app.FLDR_SAMPLING + '/SURVEYS.csv'):\n",
    "    df_surveys = pd.read_csv (app.FLDR_SAMPLING + '/SURVEYS.csv' , sep=CSV_SEPARATOR, keep_default_na=False)\n",
    "    df_surveys.columns= df_surveys.columns.str.lower()\n",
    "else:\n",
    "    df_surveys = pd.DataFrame(columns = ['survey_id','name','date'])\n",
    "df_surveys['new_entry'] = 0\n",
    "\n",
    "def get_date_name (row):\n",
    "    new_val = str(row['date']) + '___' + str(row['name'])\n",
    "    return new_val\n",
    "\n",
    "def get_unprocessed_survey_dirs(df_saved_surveys):\n",
    "    # get list of processed survey dirs\n",
    "    \n",
    "    surveys_dict = {}\n",
    "    print('Count of previously processed survey dirs: {}'.format(str(len(df_saved_surveys['name'].values))))\n",
    "    \n",
    "    for index, row in df_saved_surveys.iterrows(): \n",
    "        surveys_dict[row[SURVEYS_COL_NAME]] = row[SURVEYS_COL_DATE]\n",
    "\n",
    "    # find potential unprocessed survey dirs by iterating over folder names in s_drive and, \n",
    "    # comparing names to previously processed list\n",
    "    df = pd.DataFrame(columns=['name','date'])\n",
    "    \n",
    "    for folder in glob.iglob(app.FLDR_SAMPLING + '/**/', recursive=False):\n",
    "        survey_name = folder.split('/')[2]\n",
    "        #print(survey_name)\n",
    "        if 'notebooks' not in survey_name and 'Sampling R Code' not in survey_name and survey_name not in surveys_dict:\n",
    "            match_date = re.search(r'\\d{4}-\\d{2}-\\d{2}', folder.split('/')[-1])\n",
    "            if match_date != None:\n",
    "                survey_date = datetime.strptime(match_date.group(), '%Y-%m-%d').date()\n",
    "            else:\n",
    "                t = os.path.getmtime(folder)\n",
    "                survey_date = datetime.fromtimestamp(t)\n",
    "\n",
    "            surveys_dict[survey_name] = survey_date\n",
    "            #print('{}, on {}'.format(survey_name, survey_date.strftime('%Y-%m-%d')))\n",
    "            new_row = {'name':survey_name, 'date': survey_date.strftime('%Y-%m-%d')}\n",
    "            df = df.append(new_row, ignore_index=True)\n",
    "\n",
    "    if len(df) > 0: # found new records, append to db\n",
    "        return df\n",
    "    else:\n",
    "        df = pd.DataFrame(columns = [SURVEYS_COL_NAME, SURVEYS_COL_DATE])\n",
    "        return df\n",
    "\n",
    "### Get a dataframe of surveys that have not been processed\n",
    "df_unprocessed_survey_dirs = get_unprocessed_survey_dirs(df_surveys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f18e35",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### Please select the survey directories you would like to process. \n",
    "\n",
    "print('Count of unprocessed survey dirs: {}'.format(str(len(df_unprocessed_survey_dirs))))\n",
    "if df_unprocessed_survey_dirs is None:\n",
    "    print('There are no new survey directories to process :)')\n",
    "else:\n",
    "    # Allow user's to select which surveys, if any, they want to exclude\n",
    "    qgrid_sheet_to_keep = app.keep_grid_show_filter(df_unprocessed_survey_dirs, 'name', None, app.KEEP_LIST_SURVEY_DIRS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad98ec5",
   "metadata": {},
   "source": [
    "## Apply changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d090dce7",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### Apply filtering \n",
    "#\n",
    "# To just get the dataframe returned by qgrid_sheet_to_keep, just run the next 2 lines s\n",
    "#df_filter_by = qgrid_sheet_to_keep.get_changed_df()\n",
    "#df_filter_by.head(40)\n",
    "\n",
    "df_filtered_list_of_survey_dirs, app.KEEP_LIST_SURVEY_DIRS = app.keep_grid_apply_filter(qgrid_sheet_to_keep, 'name', df_unprocessed_survey_dirs, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554e4b08",
   "metadata": {},
   "source": [
    "# Process survey information in selected directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cde00b6",
   "metadata": {
    "code_folding": [
     0,
     6
    ]
   },
   "outputs": [],
   "source": [
    "### Iterate over directories and process survey information \n",
    "\n",
    "df_post_merge = None\n",
    "df_current_dir = pd.DataFrame(columns = ['member_id','email', 'firstname', 'lastname', 'job_title', 'last_survey_date'])\n",
    "df_surveyed_members_to_processed = None\n",
    "\n",
    "for index, row in df_filtered_list_of_survey_dirs.iterrows(): \n",
    "    df_concatenated = pd.DataFrame(columns = ['email', 'last_survey_date', 'member_id', 'firstname', 'lastname', 'job_title'])\n",
    "\n",
    "    print('folder  name: ' + row['name'])\n",
    "    df_current_file = None\n",
    "    df_post_merge = None\n",
    "    df_current_dir = None\n",
    "    #df_current_dir = pd.DataFrame(columns = ['member_id','email', 'firstname', 'lastname', 'job_title', 'last_survey_date'])\n",
    "    \n",
    "    survey_id = len(df_surveys.index)\n",
    "    #df_surveys['new_entry'] = 0\n",
    "    survey_dir = {}\n",
    "    survey_dir = {'survey_id': survey_id, 'name': row['name'], 'date': row['date'], 'new_entry': 1, }\n",
    "    df_surveys = df_surveys.append(survey_dir, ignore_index = True)\n",
    "    \n",
    "    for filename in glob.iglob(app.FLDR_SAMPLING + '/' + row['name'] + '/**/*.[cC][sS][vV]', recursive=True):\n",
    "        if 'qualtrics' in filename.lower():\n",
    "            print('  -- ' + filename)\n",
    "            \n",
    "            # read csv from directory\n",
    "            #df_current_file = None\n",
    "            df_current_file = pd.read_csv(filename)\n",
    "            df_current_file = df_current_file.rename(columns=str.lower)\n",
    "            df_current_file['last_survey_date'] = row['date']\n",
    "            df_current_file['survey_name'] = row['name']\n",
    "            df_current_file['survey_id'] = survey_id\n",
    "            df_current_file['email'] = df_current_file['email'].str.lower()\n",
    "            df_current_file['email'] = df_current_file['email'].str.strip()\n",
    "            df_current_file = df_current_file.rename({'fname' : 'first_name'}, axis=1)\n",
    "            df_current_file = df_current_file.rename({'firstname' : 'first_name'}, axis=1)\n",
    "            df_current_file = df_current_file.rename({'lname' : 'last_name'}, axis=1)\n",
    "            df_current_file = df_current_file.rename({'lastname' : 'last_name'}, axis=1)\n",
    "            #df_current_file = df_current_file.drop(['first_name', 'last_name'], axis=1)\n",
    "            \n",
    "            #df_current_file.head()\n",
    "            #print('  -- survey respondents loaded from CSV: {}'.format(str(len(df_current_file))))\n",
    "            #df_current_file.sort_values('email', inplace = True)\n",
    "            df_current_file.drop_duplicates(subset ='email', keep = 'first', inplace = True)\n",
    "            #print('  -- survey respondents (after dropping dups): {}'.format(str(len(df_current_file))))\n",
    "            \n",
    "            \n",
    "            #merge current CSV with other CSVs processed this session\n",
    "            df_surveyed_members_to_processed = pd.concat([df_surveyed_members_to_processed, df_current_file], axis=0)\n",
    "            print('  -- df_surveyed_members_to_processed {}'.format(str(len(df_surveyed_members_to_processed))))\n",
    "            \n",
    "#df_surveyed_members_to_processed.head()\n",
    "#print('df_surveyed_members_to_processed {}'.format(str(len(df_surveyed_members_to_processed))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a3ecd0",
   "metadata": {},
   "source": [
    "# Save to db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8909c50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb4e1f3",
   "metadata": {
    "code_folding": [
     0,
     2,
     10,
     18,
     34,
     47
    ]
   },
   "outputs": [],
   "source": [
    "### Merge with All Active Roster to get true names and member_ids \n",
    "\n",
    "def __create_missing_member_id(member_id):\n",
    "    str_member_id = str(member_id)\n",
    "    \n",
    "    if len(str_member_id) == 0:\n",
    "        str_member_id = uuid.uuid4()\n",
    "    \n",
    "    return str_member_id\n",
    "\n",
    "def __reassign_member_id(member_id, member_id_y):\n",
    "    str_member_id = str(member_id)\n",
    "    \n",
    "    if len(member_id_y) > 0:\n",
    "        str_member_id = member_id_y\n",
    "    \n",
    "    return str_member_id\n",
    "\n",
    "def merge_with_all_active_roster(df_left, df_right):\n",
    "    df = None\n",
    "    df = pd.merge(left=df_left, right=df_right, how='left', left_on='email', right_on='email')\n",
    "    df.drop_duplicates(subset =['survey_id', 'email'], inplace = True)\n",
    "    df['firstname'] = df['firstname'].fillna('')\n",
    "    df['lastname'] = df['lastname'].fillna('')\n",
    "    df['job_title'] = df['job_title'].fillna('')\n",
    "    df['member_id'] = df['member_id'].fillna('')\n",
    "    df['member_id'] = df.apply(lambda x: __create_missing_member_id(str(x['member_id']).strip()), axis=1)     \n",
    "    df['firstname'] = df['first_name']\n",
    "    df['lastname'] = df['last_name']\n",
    "    \n",
    "    print('  -- merge_with_all_active_roster: {}'.format(str(len(df))))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def assign_proper_member_id(df):\n",
    "    df.sort_values(['email', 'last_survey_date'], inplace = True, ascending = [True, False])\n",
    "    df_post_merge_unique_member_id = None\n",
    "    df_post_merge_unique_member_id = df.drop_duplicates(subset =['email'], inplace = False, keep = 'first')\n",
    "    df_post_merge_unique_member_id = df_post_merge_unique_member_id[['email', 'member_id']]\n",
    "    df = pd.merge(left=df_post_merge_unique_member_id, right=df, how='left', left_on='email', right_on='email')\n",
    "    df = df.rename(columns={'member_id_x': 'member_id'})\n",
    "    df = df[['member_id','email', 'firstname', 'lastname', 'job_title', 'last_survey_date', 'survey_name', 'survey_id']]\n",
    "    df.sort_values(['email', 'last_survey_date'], inplace = True, ascending = [True, False])\n",
    "\n",
    "    print('  -- assign_proper_member_id: {}'.format(str(len(df))))\n",
    "    return df\n",
    "\n",
    "def assign_autogenerated_member_id_from_prev_survey(df_left):\n",
    "    if os.path.exists(app.FLDR_SAMPLING + '/SURVEYED_MEMBERS.csv'):\n",
    "        df_right = pd.read_csv (app.FLDR_SAMPLING + '/SURVEYED_MEMBERS.csv' , sep=CSV_SEPARATOR, keep_default_na=False)\n",
    "        df_right.columns= df_right.columns.str.lower()\n",
    "    else:\n",
    "        df_right = pd.DataFrame(columns = ['member_id','email', 'firstname', 'lastname', 'job_title', 'last_survey_date'])\n",
    "\n",
    "    if len(df_right) > 0:\n",
    "        print('  -- records loaded from ' + app.FLDR_SAMPLING + '/SURVEYED_MEMBERS.csv: ' + str(len(df_right)))\n",
    "        \n",
    "        df = None\n",
    "        df = pd.merge(left=df_left, right=df_right, how='left', left_on='email', right_on='email')\n",
    "        df = df.rename(columns={'member_id_x': 'member_id'})\n",
    "        df = df.rename(columns={'firstname_x': 'firstname'})\n",
    "        df = df.rename(columns={'lastname_x': 'lastname'})\n",
    "        df = df.rename(columns={'job_title_x': 'job_title'})\n",
    "        df = df.rename(columns={'last_survey_date_x': 'last_survey_date'})\n",
    "        df['member_id_y'] = df['member_id_y'].fillna('')\n",
    "\n",
    "        df['member_id'] = df.apply(lambda x: __reassign_member_id(str(x['member_id']).strip(), str(x['member_id_y']).strip()), axis=1)   \n",
    "\n",
    "        #df_post_merge2.head(n=50)\n",
    "        df = df[['member_id','email', 'firstname', 'lastname', 'job_title', 'last_survey_date', 'survey_name', 'survey_id']]\n",
    "        df.sort_values(['email', 'last_survey_date'], inplace = True, ascending = [True, False])\n",
    "\n",
    "        print('  -- assign_autogenerated_member_id_from_prev_survey: {}'.format(str(len(df))))\n",
    "        return df, df_right\n",
    "    else:\n",
    "        print('  -- assign_autogenerated_member_id_from_prev_survey: {}'.format(str(len(df_left))))\n",
    "        return df_left, df_right\n",
    "\n",
    "if df_surveyed_members_to_processed is not None:\n",
    "    df_post_merge = None\n",
    "    df_post_merge = merge_with_all_active_roster(df_surveyed_members_to_processed, df_complete_list)\n",
    "    #df_post_merge.head()\n",
    "\n",
    "    df_post_merge = assign_proper_member_id(df_post_merge)\n",
    "    #df_post_merge.head(n=50)\n",
    "\n",
    "    df_post_merge, df_surveyed_members = assign_autogenerated_member_id_from_prev_survey(df_post_merge)\n",
    "    #df_post_merge.head(n=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e850cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b598bf",
   "metadata": {
    "code_folding": [
     0,
     2
    ]
   },
   "outputs": [],
   "source": [
    "### Process df to determine surveys to save to app.FLDR_SAMPLING + '/SURVEYS_TO_MEMBERS.csv' \n",
    "\n",
    "if df_surveyed_members_to_processed is not None:\n",
    "    df_surveys_to_members_temp = None\n",
    "    df_surveys_to_members_temp = df_post_merge[['survey_id', 'member_id', 'email']]\n",
    "    df_surveys_to_members_temp.sort_values(['survey_id', 'email'], inplace = True)\n",
    "    df_surveys_to_members_temp.drop_duplicates(subset =['survey_id', 'email'], inplace = True)\n",
    "    df_surveys_to_members_temp = df_surveys_to_members_temp[['survey_id', 'member_id']]\n",
    "    len(df_surveys_to_members_temp)\n",
    "    #df_surveys_to_members_temp = pd.concat([df_surveys_to_members_temp, df_surveys_to_members], axis=0)\n",
    "    #df_surveys_to_members_temp.sort_values(['survey_id', 'member_id'], inplace = True)\n",
    "    #df_surveys_to_members_temp.drop_duplicates(subset = ['survey_id', 'member_id'], keep = 'first', inplace = True)\n",
    "    #df_surveys_to_members = df_surveys_to_members_temp\n",
    "\n",
    "    if os.path.exists(app.FLDR_SAMPLING + '/SURVEYS_TO_MEMBERS.csv'):\n",
    "        df_surveys_to_members_temp.to_csv(app.FLDR_SAMPLING + '/SURVEYS_TO_MEMBERS.csv', mode = 'a', header = False, index=False, quotechar='\"')\n",
    "    else:\n",
    "        df_surveys_to_members_temp.to_csv(app.FLDR_SAMPLING + '/SURVEYS_TO_MEMBERS.csv', mode = 'w', header = True, index=False, quotechar='\"')\n",
    "        #df_surveys_to_members_temp.head()\n",
    "\n",
    "    #df_surveys_to_members_temp.to_csv(app.FLDR_SAMPLING + '/SURVEYS_TO_MEMBERS.csv', mode = 'w', header = True, index=False, quotechar='\"')\n",
    "    print('  -- df_surveys_to_members_temp: {}'.format(str(len(df_surveys_to_members_temp))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbcad76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352424ae",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### Process df to save to app.FLDR_SAMPLING + '/SURVEYS.csv' \n",
    "    df_surveys_temp = df_surveys[df_surveys['new_entry']==1]\n",
    "    df_surveys_temp = df_surveys_temp[['survey_id', 'name', 'date']]\n",
    "\n",
    "    if os.path.exists(app.FLDR_SAMPLING + '/SURVEYS.csv'):\n",
    "        df_surveys_temp.to_csv(app.FLDR_SAMPLING + '/SURVEYS.csv', mode = 'a', header = False, index=False, quotechar='\"')\n",
    "    else:\n",
    "        df_surveys_temp.to_csv(app.FLDR_SAMPLING + '/SURVEYS.csv', mode = 'w', header = True, index=False, quotechar='\"')\n",
    "\n",
    "    df_surveys['new_entry'] = 0\n",
    "    #df_surveys.head()\n",
    "    print('  -- df_surveys_temp: {}'.format(str(len(df_surveys_temp))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001601e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510081f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23792a43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080bb55e",
   "metadata": {
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [],
   "source": [
    "### Process df to save to app.FLDR_SAMPLING + '/SURVEYED_MEMBERS.csv' \n",
    "if df_surveyed_members_to_processed is not None:\n",
    "    df_surveyed_members_temp = None\n",
    "    df_surveyed_members_temp = df_post_merge[['member_id','email', 'firstname', 'lastname', 'job_title', 'last_survey_date']]\n",
    "    df_surveyed_members_temp.sort_values(['email','last_survey_date'], inplace = True)\n",
    "    df_surveyed_members_temp.drop_duplicates(subset =['email'], inplace = True)\n",
    "\n",
    "    df_surveyed_members_temp = pd.concat([df_surveyed_members_temp, df_surveyed_members], axis=0)\n",
    "    df_surveyed_members_temp.sort_values(['email','last_survey_date'], inplace = True)\n",
    "    df_surveyed_members_temp.drop_duplicates(subset =['email'], inplace = True)\n",
    "    df_surveyed_members = df_surveyed_members_temp\n",
    "\n",
    "    #if os.path.exists(app.FLDR_SAMPLING + '/SURVEYED_MEMBERS.csv'):\n",
    "    #    df_surveyed_members_temp.to_csv(app.FLDR_SAMPLING + '/SURVEYED_MEMBERS.csv', mode = 'a', header = Fa, index=False, quotechar='\"')\n",
    "    #else:\n",
    "    #    df_surveyed_members_temp.to_csv(app.FLDR_SAMPLING + '/SURVEYED_MEMBERS.csv', mode = 'w', header = True, index=False, quotechar='\"')\n",
    "    #    #df_surveyed_members_temp.head()\n",
    "\n",
    "    df_surveyed_members_temp.to_csv(app.FLDR_SAMPLING + '/SURVEYED_MEMBERS.csv', mode = 'w', header = True, index=False, quotechar='\"')\n",
    "    print('  -- df_surveyed_members_temp: {}'.format(str(len(df_surveyed_members_temp))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cc455f",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### Show number of surveys left to process \n",
    "processed_surveys = df_filtered_list_of_survey_dirs['name'].values\n",
    "df_unprocessed_survey_dirs = df_unprocessed_survey_dirs[~df_unprocessed_survey_dirs['name'].isin(processed_surveys)]\n",
    "\n",
    "if len(df_unprocessed_survey_dirs) == 0:\n",
    "    df_unprocessed_survey_dirs = None\n",
    "\n",
    "print('Number of survey directories left to process: {}'.format(str(len(df_unprocessed_survey_dirs))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296d137f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614e4640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46695413",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
